---
title: "Jevons Paradox, bike-shedding, and 3 reasons why Generative AI mostly terrifies me"
date: 2024-06-02T13:50:41-04:00
draft: false
tags: ["generative-ai"]
weight: 2
featuredImage: "/images/ahasha_A_realistic_dystopian_scene_of_a_humanoid_robot_building_2acb1d5c-d69b-4f20-bfe6-18eb6469346c.png"
featuredImagePreview: "/images/ahasha_A_realistic_dystopian_scene_of_a_humanoid_robot_building_60e3ed80-a713-4f0e-8b5d-0d4b1739040a.png"
---

This may be  the understatement of the year, but Generative AI is having a moment.  Even as a long-time practitioner in Machine Learning, I was amazed how suddenly AI passed the Turing test and how rapidly it has advanced since hitting the mass.  Like many professionals, I've tried hard to incorporate it in my day-to-day workflows both because it obviously has immense promise, but also because I'm afraid of being left behind if I ignore it.

Don't get me wrong, it's already useful and the promise is real.  But the more I dig into real use cases, the more concerned I get about the negative side effects of broad adoption.   Two concepts, Jevons Paradox and "Bike Shedding", help crystalize what I'm worried about.

[Jevons Paradox](https://en.wikipedia.org/wiki/Jevons_paradox) is an economics term for the observation that, as technological progress increases the efficiency with which a resource is used, the overall consumption of that resource can actually increase rather than decrease. This happens if falling costs drives increased demand that outweighs the efficiency gain.  A commonly cited example is that widening a highway can actually make traffic worse.  Professionally, I put a lot of energy into automating analytical processes, making them more efficient to produce, but this has never resulted in me having more free time.  Instead, expectations for the quality and quantity of analytical work always rise to consume whatever capacity I add.

"Bike-shedding" is a popular term for [Parkinson's Law of Triviality](https://en.wikipedia.org/wiki/Law_of_triviality): the all-too-human tendency to focus on the tasks that make us feel least anxious, with the result that we put disproportionate energy into trivial issues.  In his 1957 book, Parkinson illustrated this concept with an example of a committee tasked with approving plans for a nuclear power plant. Instead of focusing on the complex and significant aspects of the power plant, the committee spent a disproportionate amount of time discussing relatively minor issues, like the design of a bike shed.

What does this have to do with Generative AI?  Here are three things that terrify me:

1. **It won't save us time on writing, it will just mean we have to write a lot more**: Generative AI is drastically reducing the cost to produce mountains of seemingly competent prose, but not the effort required for a human to read, understand, and evaluate it.  Jevons Paradox suggests that, rather than saving us time on our writing tasks, we'll simply find ourselves expected to produce a lot more writing overall.  Norms will shift such that, even if you prefer to do your own thinking and use Generative AI responsibly, there will be growing pressure to keep pace with the folks churning out large volumes of AI-generated pseudo-thinking.

2. **We'll need to read even more, and it will be harder to trust what we read**: The existence of a document with good formatting and grammar used to be prima facie evidence that one or more humans spent time thinking about the topics it covers.  So much of our management and regulatory oversight practices rely on this fact.  Reading and evaluating a document should take less time than writing it.  Now, the people responsible for evaluating written work will find themselves in an arms race with teams using AI.  They'll produce more and more pages of stuff, and the effort required to discern if the humans responsible for the document actually know what they're talking about will increase dramatically.  The temptation for reviewers to start using AI to summarize all this AI-generated material will be strong.  Do you we really want to live in a world where you pay OpenAI to expand your bullet points into 5000 words of prose, then I pay OpenAI to condense them back down to a bullet list?

3. **It will add more trivial time-sucks to our lives**:  The temptation to bike-shedding is closely related to Jevons Paradox: the less it costs us to resolve a problem, the more psychological pressure we feel to do so. Google drastically reduced the cost of satisfying your curiosity when a question pops into your mind.  If you're old enough to remember life before Google, would you say you spend more or less time today looking up the answers to questions?  And what percentage of the time you devote to Google are you just scratching an itch rather than focusing on your real priorities?  Similarly with stuff, it's never been easier and cheaper to buy a specialized gadget to resolve any household problem, but as we're clicking "1-day shipping buy now!" we're generally forgetting about the time we will spend cleaning, organizing, configuring, repairing, and disposing of all those "solutions".  Unless we get better at resisting such temptations, AI assistants won't just cut down how long it takes us to complete trivial tasks, they will entice us to take on more of them.

Now, I'm not an AI luddite, and these problems aren't new.   I expect Generative AI will eventually be at least as transformative as personal computing, mobile computing, and web personalization have been.  In many ways, AI is simply accelerating trends that these technologies began, for good and for ill.

Let's savor the wonder and excitement of this new phase of the machine intelligence revolution.  However, past experience should prompt us to take care that new technology serves us, and not the other way around.  More than ever, we need the mindfulness to choose and focus on meaningful priorities, and not let technology entice us down the path of least resistance.  That will take strong critical evaluation skills.  As AI gets rapidly better at putting the sheen of professionalism on careless work, we need to be able to discern the trustworthiness information based on fundamentals, not formatting or entertainment value.

Easier isn't always better. Any complex system needs a balance of friction and lubrication to function well, and thought work is no different.  Let's make sure that, in the race to remove friction from our lives, we're clearing space to put our energy into things that matter.